Simple RL agent, key elements:

Monte Carlo algorithm for learning the V-value function.
V-value array implementation.
Choosing the best action based on the V-value array.
Algorithm to update the V-values based on the collected episodes.
Two exploration methods: e-greedy and GLIE.
Selection of the maximum length of episodes, number of episodes and epochs.

Results for the most optimal hyperparameters:
-0.5 penalty for each turn:

![image16](https://github.com/user-attachments/assets/00a0dc2c-3b3f-4b64-a4cf-16d864ab7956)

-0.1 penalty for each turn:

![image6](https://github.com/user-attachments/assets/d1ca43f7-9295-42c6-abed-089bc88ad4e5)
